"""
Adjoint-based optimization using Firedrake's automatic differentiation

Key changes:
1. Forward model must use Firedrake operations (not NumPy where possible)
2. Parameters become Control objects
3. Gradients computed via adjoint equations (much faster!)
"""

import numpy as np
from firedrake import *
from firedrake.adjoint import *
from pyadjoint import get_working_tape, Control, ReducedFunctional
from typing import Dict, Tuple


class AdjointParameterOptimizer(ParameterOptimizer):
    """
    Adjoint-based parameter optimizer
    
    Inherits from ParameterOptimizer but uses adjoint gradients
    """
    
    def __init__(
        self,
        forward_model_adjoint: Callable,  # Special adjoint-compatible forward model
        observations: ObservationData,
        bounds: ParameterBounds,
        initial_params: Dict[str, float],
        config,  # Need simulation config
        probe_positions: List[Tuple]
    ):
        """
        Args:
            forward_model_adjoint: Adjoint-compatible forward model (returns solver object)
            observations: Same as before
            bounds: Same as before
            initial_params: Same as before
            config: SimulationConfig object
            probe_positions: List of probe coordinates
        """
        self.forward_model_adjoint = forward_model_adjoint
        self.observations = observations
        self.bounds = bounds
        self.param_names = bounds.names
        self.config = config
        self.probe_positions = probe_positions
        
        # Transform to optimization space
        self.current_params = self._to_opt_space(initial_params)
        
        # History
        self.loss_history = []
        self.param_history = []
        
        # Adjoint-specific
        self.controls = None
        self.reduced_functional = None
    
    def setup_adjoint_problem(self, params: Dict[str, float]):
        """
        Setup the adjoint problem with controls
        
        This runs the forward model once to build the tape
        """
        # Clear previous tape
        tape = get_working_tape()
        tape.clear_tape()
        
        # Create Firedrake Constants for parameters (these will be controls)
        param_constants = {name: Constant(val) for name, val in params.items()}
        
        # Run forward model (this records operations on the tape)
        solver = self.forward_model_adjoint(param_constants)
        
        # Extract simulated values at probe locations
        simulated_values = self._extract_probe_values(solver)
        
        # Build loss functional
        J = self._build_loss_functional(simulated_values)
        
        # Define controls (parameters to optimize)
        self.controls = [Control(param_constants[name]) for name in self.param_names]
        
        # Create reduced functional
        self.reduced_functional = ReducedFunctional(J, self.controls)
        
        return J
    
    def _extract_probe_values(self, solver) -> List[List[float]]:
        """
        Extract water table values at probe locations from solver
        
        Returns:
            List of lists [n_times][n_probes]
        """
        probe_data = solver.probe_manager.get_data()
        times = probe_data['times']
        n_times = len(times)
        n_probes = len(self.probe_positions)
        
        simulated = []
        for i in range(n_times):
            time_values = []
            for probe_idx in range(n_probes):
                probe_name = f'Probe_{probe_idx + 1}'
                val = probe_data['data'][probe_name]['water_table'][i]
                time_values.append(val)
            simulated.append(time_values)
        
        return simulated
    
    def _build_loss_functional(self, simulated_values: List[List[float]]) -> AdjFloat:
        """
        Build loss functional as sum of squared residuals
        
        This needs to use Firedrake operations to be differentiable
        """
        # Cut off first 20% (warm-up period)
        cutoff = int(0.2 * len(simulated_values))
        
        loss = AdjFloat(0.0)
        n_active = 0
        
        for t_idx in range(cutoff, len(simulated_values)):
            for probe_idx in range(len(self.probe_positions)):
                sim_val = simulated_values[t_idx][probe_idx]
                obs_val = self.observations.values[t_idx, probe_idx]
                weight = self.observations.weights[t_idx, probe_idx]
                
                residual = sim_val - obs_val
                loss += weight * residual**2
                n_active += weight
        
        # Normalize
        loss = loss / n_active
        
        return loss
    
    def compute_gradient_adjoint(self, params: Dict[str, float]) -> np.ndarray:
        """
        Compute gradient using adjoint method
        
        This is MUCH faster than finite differences for many parameters
        """
        # Setup problem (runs forward and builds tape)
        self.setup_adjoint_problem(params)
        
        # Compute adjoint gradients
        gradients = self.reduced_functional.derivative()
        
        # Convert to numpy array
        grad_array = np.array([float(g) for g in gradients])
        
        return grad_array
    
    def optimize(
        self,
        n_iterations: int = 50,
        learning_rate: float = 0.05,
        optimizer_type: str = 'adam',
        verbose: bool = True
    ) -> Dict[str, float]:
        """
        Run adjoint-based optimization
        
        Args:
            n_iterations: Number of iterations
            learning_rate: Learning rate
            optimizer_type: 'adam', 'lbfgs', or 'sgd'
            verbose: Print progress
            
        Returns:
            Optimized parameters
        """
        # Setup PyTorch optimizer
        if optimizer_type == 'adam':
            optimizer = torch.optim.Adam([self.current_params], lr=learning_rate)
        elif optimizer_type == 'lbfgs':
            optimizer = torch.optim.LBFGS([self.current_params], lr=learning_rate, max_iter=20)
        else:
            optimizer = torch.optim.SGD([self.current_params], lr=learning_rate)
        
        if verbose:
            print(f"Starting ADJOINT optimization: {len(self.param_names)} parameters, {n_iterations} iterations")
            print()
        
        for iteration in range(n_iterations):
            def closure():
                optimizer.zero_grad()
                
                # Get physical params
                params = self._to_physical_space(self.current_params)
                
                # Setup and run forward problem (builds tape)
                J = self.setup_adjoint_problem(params)
                loss = float(J)
                
                # Store history
                self.loss_history.append(loss)
                self.param_history.append(params.copy())
                
                if verbose and (iteration % 5 == 0 or iteration == 0):
                    print(f"Iter {iteration:3d}: Loss = {loss:.6e}")
                    for name, val in params.items():
                        print(f"  {name:12s} = {val:.6e}")
                    print()
                
                # Compute adjoint gradients
                grad_physical = self.reduced_functional.derivative()
                grad_physical_np = np.array([float(g) for g in grad_physical])
                
                # Transform gradients to optimization space (chain rule)
                sigmoid_vals = torch.sigmoid(self.current_params)
                transform_grad = sigmoid_vals * (1 - sigmoid_vals)
                
                scales = torch.tensor([self.bounds.get(name)[1] - self.bounds.get(name)[0] 
                                      for name in self.param_names])
                
                self.current_params.grad = torch.tensor(grad_physical_np) * transform_grad * scales
                
                return torch.tensor(loss)
            
            optimizer.step(closure)
            
            # Check convergence
            if len(self.loss_history) > 1:
                rel_change = abs(self.loss_history[-1] - self.loss_history[-2]) / (self.loss_history[-2] + 1e-10)
                if rel_change < 1e-4:
                    if verbose:
                        print(f"\nConverged after {iteration + 1} iterations (rel_change={rel_change:.6e})")
                    break
        
        # Return best parameters
        best_idx = np.argmin(self.loss_history)
        if verbose:
            print(f"\nOptimization complete. Best loss: {self.loss_history[best_idx]:.6e}")
        
        return self.param_history[best_idx]


# ==============================================================================
# ADJOINT-COMPATIBLE FORWARD MODEL
# ==============================================================================

def forward_model_adjoint(param_constants: Dict[str, Constant]) -> 'RichardsSolver':
    """
    Adjoint-compatible forward model
    
    Just pass the Constant objects directly to your existing Material.till()
    """
    config = SimulationConfig(...)
    
    domain = Domain(nx=80, ny=40, Lx=20.0, Ly=5.0)
    
    # Your existing Material.till() - just pass Constants instead of floats
    domain.assign("base", Material.till(
        theta_r=param_constants['theta_r'],  # Constant, not float
        theta_s=param_constants['theta_s'],
        alpha=param_constants['alpha'],
        n=param_constants['n'],
        Ks=param_constants['Ks']
    ))
    
    Returns:
        RichardsSolver object with completed simulation
    """
    # Extract constants
    theta_r = param_constants['theta_r']
    theta_s = param_constants['theta_s']
    alpha = param_constants['alpha']
    n = param_constants['n']
    Ks = param_constants['Ks']
    rain_mult_0 = param_constants['rain_mult_0']
    rain_mult_1 = param_constants['rain_mult_1']
    wt_left = param_constants['wt_left']
    wt_right = param_constants['wt_right']
    wt_trend = param_constants['wt_trend']
    
    # IMPORTANT: Use the constants directly in Material creation
    # This allows gradients to flow through
    
    config = SimulationConfig(
        name="Adjoint_Optimization",
        start_datetime=datetime(2024, 4, 15),
        end_datetime=datetime(2024, 6, 30),
        dt_td=timedelta(hours=6)
    )
    
    rain_zones = [
        {'name': 'grass', 'x_min': 0.0, 'x_max': 8.0, 'multiplier': rain_mult_0},
        {'name': 'green_infra', 'x_min': 9.0, 'x_max': 11.0, 'multiplier': rain_mult_1},
    ]
    
    rain_source = rainfall_scenario(
        from_date=config.start_datetime,
        to_date=config.end_datetime,
        meteostat_station='SOK6B',
        meteostat_agg_hours=6,
        zones=rain_zones
    )
    
    domain = Domain(nx=80, ny=40, Lx=20.0, Ly=5.0)
    
    # CRITICAL: Material needs to accept Constant objects
    # You may need to modify Material.till() to handle this
    domain.assign("base", Material.till_from_constants(
        theta_r=theta_r,
        theta_s=theta_s,
        alpha=alpha,
        n=n,
        Ks=Ks
    ))
    
    V = FunctionSpace(domain.mesh, "CG", 1)
    field_map = MaterialField(domain, V)
    
    # Boundary conditions with constants
    bc_manager = BoundaryConditionManager(
        V, wt_left, wt_right,
        left_trend=(config.end_datetime, wt_left - wt_trend),
        right_trend=(config.end_datetime, wt_right - wt_trend),
        time_converter=config.time_converter
    )
    
    probe_manager = ProbeManager(
        domain.mesh,
        probe_positions=[[8.0, 1.0], [10.0, 1.0], [12.5, 1.0]]
    )
    
    solver = RichardsSolver(
        domain=domain,
        V=V,
        field_map=field_map,
        source_scenario=rain_source,
        bc_manager=bc_manager,
        config=config
    )
    
    # Run simulation (tape records everything)
    solver.run(probe_manager)
    
    return solver


# ==============================================================================
# MATERIAL CLASS MODIFICATION (needed for adjoint)
# ==============================================================================

class Material:
    """Add this method to your Material class"""
    
    @staticmethod
    def till_from_constants(theta_r, theta_s, alpha, n, Ks):
        """
        Create material from Firedrake Constants (for adjoint)
        
        This version accepts Constant objects instead of floats
        """
        material = Material()
        material.theta_r = theta_r
        material.theta_s = theta_s
        material.alpha = alpha
        material.n = n
        material.m = 1 - 1/n  # This creates a UFL expression
        material.Ks = Ks
        
        # Define theta(psi) and K(psi) as UFL expressions
        # These will be differentiable
        def theta_psi_expr(psi):
            Se = (1 + abs(alpha * psi)**n)**(-material.m)
            return theta_r + (theta_s - theta_r) * Se
        
        def K_psi_expr(psi):
            Se = (1 + abs(alpha * psi)**n)**(-material.m)
            return Ks * Se**0.5 * (1 - (1 - Se**(1/material.m))**material.m)**2
        
        material.theta_psi = theta_psi_expr
        material.K_psi = K_psi_expr
        
        return material


# ==============================================================================
# USAGE EXAMPLE
# ==============================================================================

def main_adjoint():
    """Run adjoint-based optimization"""
    
    # Load observations (same as before)
    LTC_data = load_measured_data(
        start_datetime=datetime(2024, 4, 15),
        end_datetime=datetime(2024, 6, 30) + timedelta(hours=6),
        time_converter=TimeConverter(datetime(2024, 4, 15)),
        align=True,
        align_freq=6
    )
    
    observations = ObservationData(
        times=LTC_data['times'],
        locations=[[8.0, 1.0], [10.0, 1.0], [12.5, 1.0]],
        values=np.array([LTC_data['LTC 101'], LTC_data['LTC 102'], LTC_data['LTC 103']]).T
    )
    
    # Parameters and bounds (same as before)
    base_params = {
        'theta_r': 0.02,
        'theta_s': 0.14,
        'alpha': 0.9399,
        'n': 2.3579,
        'Ks': 9e-6,
        'rain_mult_0': 1.0,
        'rain_mult_1': 6.0,
        'wt_left': 0.6,
        'wt_right': 1.5,
        'wt_trend': 0.25
    }
    
    initial_params, bounds = create_tight_bounds(base_params, variation_pct=20.0)
    
    # Create adjoint optimizer
    optimizer = AdjointParameterOptimizer(
        forward_model_adjoint=forward_model_adjoint,
        observations=observations,
        bounds=bounds,
        initial_params=initial_params,
        config=None,  # Will be created in forward model
        probe_positions=[[8.0, 1.0], [10.0, 1.0], [12.5, 1.0]]
    )
    
    # Run optimization
    print("Running adjoint-based optimization...\n")
    best_params = optimizer.optimize(
        n_iterations=50,
        learning_rate=0.1,
        optimizer_type='adam',
        verbose=True
    )
    
    # Analyze results (same as before)
    print("\nOptimized parameters:")
    for name, val in best_params.items():
        print(f"  {name:15s} = {val:.6e}")
    
    # Plot results
    plot_optimization_results(
        optimizer,
        save_path=f'adjoint_optimization_{datetime.now().strftime("%m%d_%H%M")}.png'
    )
    
    return best_params, optimizer


if __name__ == "__main__":
    best_params, optimizer = main_adjoint()